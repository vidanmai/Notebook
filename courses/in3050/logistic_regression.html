<!doctype html>
<html class="no-js" lang="">

<head>
  <meta charset="utf-8">
  <title></title>
  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="manifest" href="site.webmanifest">
  <link rel="apple-touch-icon" href="icon.png">
  <!-- Place favicon.ico in the root directory -->
  <!--Google icons -->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!-- Materialize css -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css">
  <link rel="stylesheet" href="../../css/normalize.css">
  <link rel="stylesheet" href="../../css/main.css">

  <meta name="theme-color" content="#fafafa">
</head>

<body>
   <!-- Navbar -->
   <div class="navbar-fixed">
     <nav>
       <div class="nav-wrapper" id="navbar">
         <div class="content-wrapper">
           <a href="../../index.html" class="brand-logo" id="logo">[Notebook]</a>
           <a href="#" data-target="mobile-demo" class="sidenav-trigger"><i class="material-icons"
               id="sidenav-icon">menu</i></a>
           <ul class="right hide-on-med-and-down">
             <!-- dark mode toggle -->
             <li>
               <div class="switch dark-mode-toggle" id="dark-mode-toggle">
                 <label id="dark-mode-label">
                   <img id="sun" class="darkmode-icon" src="../../icons/sun.svg" alt="">
                   <input id="dark-mode-input" type="checkbox">
                   <span class="lever"></span>
                   <img id="moon" class="darkmode-icon" src="../../icons/nights_stay-white-18dp.svg" alt="">
                 </label>
               </div>
             </li>
             <!-- dark mode toggle end  -->
             <!-- Main nav -->
             <li class="tooltipped" data-position="bottom" data-tooltip="Projects"><a href="../../projects/"><img
                   src="../../icons/rocket.svg" alt="" class="icon"></a></li>
             <li class="tooltipped" data-position="bottom" data-tooltip="Courses"><a href="../index.html"><img
                   src="../../icons/knowledge_color.svg" alt="" class="icon"></a>
             </li>
             <li class="tooltipped" data-position="bottom" data-tooltip="Blog"><a href="../../blog/"><img
                   src="../../icons/blogger.svg" alt="" class="icon"></a>
             </li>
             <li><a class="waves-effect btn red darken-2" href="../../contact.html">Contact</a></li>
           </ul>
           <!-- Main nav end -->
         </div>
       </div>
     </nav>
   </div>
   <!-- Sidenav -->
   <ul class="sidenav" id="mobile-demo">
     <li><a class="waves-effect waves-light btn indigo darken-2" href="../../projects/">Projects üöÄ</a></li>
     <li><a class="waves-effect waves-light btn green darken-2" href="../index.html">Courses üìö</a></li>
     <li><a class="waves-effect waves-light btn orange darken-2" href="../../blog/">Blog üë®‚Äçüíª</a></li>
     <li><a class="waves-effect waves-light btn red darken-2 " href="../../contact.html">Contact üìß</a></li>
     <li><a class="waves-effect waves-light center sidenav-close" href="#!" id="close-sidenav-btn">Close</a></li>
     <!-- Dark mode toggle for mobile -->
     <li>
       <div class="switch dark-mode-toggle center" id="mobile-dark-mode-toggle">
         <label id="dark-mode-label">
           Light
           <input id="mobile-dark-mode-input" type="checkbox">
           <span class="lever"></span>
           Dark
         </label>
       </div>
     </li>
     <!-- darkmode mobile toggle end  -->
   </ul>
   <!-- Navbar end -->
   <!-- Navbar end -->
   <!-- Load darkmode before other scripts -->
   <script src="../../js/darkmode.js"></script>
   <!-- Main body content -->
   <!-- Page layout -->
   <div class="row" id="main">
     <div class="col s12 hide-on-large-only">
       <!-- Dropdown links -->
       <ul id="dropdown" class="dropdown-content">
         <li><a href="#">Close</a></li>
         <li><a href="index.html">IN3050</a></li>
         <li><a href="search-and-optimization.html">Search and optimization</a></li>
         <li><a href="evolutionary_algorithms.html">Evolutionary Algorithms</a></li>
         <li><a href="machine_learning.html">Machine Learning</a></li>
         <li><a href="supervised-classification.html">Supervised classification</a></li>
         <li><a href="perceptron.html">Perceptron</a></li>
         <li><a href="linear-regression.html">Linear regression</a></li>
         <li><a href="logistic_regression.html">Logistic regression</a></li>
         <li><a href="mlp.html">Multi-Layer Perceptron Network</a></li>
       </ul>
       <!-- End dropdown links -->
       <a class="btn dropdown-trigger grey darken-4" href="" data-target="dropdown">Subjects<i
           class="material-icons right">arrow_drop_down</i></a>
     </div>
     <!-- Side course navigation -->
     <div class="col s12 m2 l2 hide-on-med-and-down">
       <div class="collection" id="course-nav">
         <a href="index.html" class="collection-item">IN3050</a>
         <a href="search-and-optimization.html" class="collection-item">Search and
           optimization</a>
         <a href="evolutionary_algorithms.html" class="collection-item">Evolutionary Algorithms</a>
         <a href="machine_learning.html" class="collection-item">Machine Learning</a>
         <a href="supervised-classification.html" class="collection-item">Supervised
           classification</a>
         <a href="perceptron.html" class="collection-item">Perceptron</a>
         <a href="linear-regression.html" class="collection-item">Linear regression</a>
         <a href="logistic_regression.html" class="collection-item active">Logistic regression</a>
         <a href="mlp.html" class="collection-item">Multi-Layer Perceptron Network</a>
         
       </div>
     </div>
     <!-- Middle content -->
     <div class="col s12 m12 l8">
        <div class="container flow-text" id="middle-content">
          <h3 class="center-align">Logistic Regression</h3>
          <img
            src="https://i0.wp.com/dataaspirant.com/wp-content/uploads/2016/04/logisticregression.png?resize=768%2C384&ssl=1"
            class="responsive-img center" alt="">
          <div class="section scrollspy">
            <h5>Introduction</h5>
            <hr>
            <p>
              Logistic regression is a classification algorithm used to assign observations to a discrete set of classes. Unlike linear regression which outputs continuous number values, logistic regression transforms its ouput using the logistic sigmoid function to return a probability value which can then be mapped to two or more discrete classes.
            </p>
          </div>
          <div class="section scrollspy">
            <h5>Comparison to Linear Regression</h5>
            <hr>
            <p>
              Given data on time spent studying and exam scores. Linear Regression and Logistic Regression can predict different things:
              <ul class="flow-text">
                <li>
                  <b>Linear Regression could help us predict the student's test score on a scale of 0-100.</b>
                </li>
                <li>
                  <b>Logistic Regression could help us predict whether the student passed or failed. Logistic Regression predictions are discrete (only specific values or categories are allowed). We can also view probability scores underlying the model's classifications.</b>
                </li>
              </ul>
            </p>
            <h5>Types of Logistic Regression</h5>
            <ul class="flow-text">
              <li>Binary (Pass/Fail)</li>
              <li>Multi (Cats, Dogs, Sheep)</li>
              <li>Ordinal (Low, Medium, High)</li>
            </ul>
          </div>
          <div class="section scrollspy">
            <h5>Binary Logistic Regression</h5>
            <hr>
            <p>
              Say we are given data on student exam results and our goal is to predict whether a student will pass or
              fail based on the number of hours slept and hours spent studying. We have two features (hours slept, hours
              studied) and two classes: passed (1) and failed (0).
            </p>
            <table>
              <thead>
                <th>Studied</th>
                <th>Slept</th>
                <th>Passed</th>
              </thead>
              <tbody>
                <tr>
                  <td>4.85</td>
                  <td>9.63</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td>8.62</td>
                  <td>3.23</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>5.43</td>
                  <td>8.23</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td>9.21</td>
                  <td>6.34</td>
                  <td>0</td>
                </tr>
              </tbody>
            </table>
            <div class="img-section">
              <img src="img/logistic_regression_exam_scores_scatter.png" alt="" class="white">
            </div>
          </div>
          <div class="section scrollspy">
            <h5>Sigmoid activation</h5>
            <hr>
            <p>In order to map predicted values to probabilities, we use the <strong>sigmoid</strong> function. The
              function maps any real value into another value between 0 and 1. In Machine Learning, we use sigmoid to
              map predictions to probabilities.</p>
            <div class="img-section">
              <img src="img/sigmoid_function.png" alt="" class="white">
            </div>
            <p>f(x) = output between 0 and 1 (probability estimate)
              <br>z = input to the function (your algorithm's prediction e.g. mx+b)
              <br>e = base of natural log
            </p>
          </div>
          <div class="section scrollspy">
            <h5>Decision Boundary</h5>
            <hr>
            <p>
              Our current prediction function returns a probability score between 0 and 1. In orderr to map this to a discrete class (true/false, cat/dog), we select a threshold value or tipping point above which we will classify values into class 1 and below which we classify values into class 2.
              </p>
              <div class="math center">
                <code>
                  p >= 0.5, class = 1
                  <br>p < 0.5, class=0
                </code>
              </div>
              <p>
                For example, if our threshold was 0.5, and our prediction function returned 0.7, we would calssify this observation as positive. If our predictionw was 0.2, we would classify the observation as negative. For logistic regression with multiple classes, we could select the class with the highest predicted probability.
              </p>
          </div>
          <div class="section scrollspy">
            <h5>Making Predictions</h5>
            <hr>
            <p>
              Using our knowledge of sigmoid functions and decision boundaries, we can now write a prediction function. A prediction function in logistic regression returns the probability of our observation being positive, True or "Yes". We call this class 1 and its notation is <i><b>P(class = 1)</b></i>. As the probability gets closer to 1, our model is more confident that the observation is in class 1.
            </p>
            <h5>Math</h5>
            <div class="math center">
              <code>
                z = W0 + W1Studied + W2Slept
              </code>
            </div>
            <p>We can transform the output using the sigmoid function to return a probability value between 0 and 1. If
              the model returns 0.4, it believes there is only a 40% chance of passing. If your decision boundary was
              0.5, we would categorize this observation as a "Fail".</p>
              <div class="img-section">
                <img src="img/sigmoid_probability.JPG" alt="" class="white">
              </div>
          </div>
          <div class="section scrollspy">
            <h5>Cost Function</h5>
            <hr>
            <p>
              In Logistic Regression, we shouldn't use the same cost function <strong>MSE (L2)</strong> as we did for linear regression. Thre reason for this is simply because our prediction function is non-linear (due to sigmoid transformation). Squaring this prediction as we do in MSE results in a non-convex function with many local minimums. If our cost function has many local minimums, gradient descent may not find the optimal global minimum.
            </p>
            <h5>Math</h5>
            <p>Instead of Mean Squared Error, we use a cost function called <strong>Cross-Entropy</strong>, also known as Log Loss. Cross-entropy loss can be divided into two separate cost functions: one for y = 1 and one for y = 0.
            </p>
            <div class="img-section">
              <img src="img/cross_entropy_loss.png" alt="" class="white">
            </div>
          </div>
          <p>
            The benefits of taking the logaritm reveal themselves when you look at the cost function graphs for y = 1 and y = 0. These smooth monotone functions (always increasing or always decreasing) make it easy to calculate the gradient and minimize the cost.
          </p>
          <div class="img-section">
            <img src="img/y1andy2_logistic_function.png" alt="" class="white">
          </div>
          <p>
            They key thing to note is that the cost function penalizes confident and wrong predictions more than it rewards confident and right predictions. The proposition is increasing prediciton accuracy (closer to 0 or 1) and has diminishing returns on reducing cost due to the logistic nature of our cost function.
          </p>
          <h5>Above functions compressed into one</h5>
          <div class="img-section">
            <img src="img/logistic_cost_function_joined.png" alt="" class="white">
          </div>
          <p>
            Multiplying by <b><i>y</i></b> and <b><i>1-y</i></b> in the above equation is a sneaky trick that let's us use the sane eqyatuib ti sikve fir bith y = 1 and y = 0 cases. If y = 0, the first side canels out. if y = 1, the second side cancels out. In both caves, we only perform the operation we need to perform.
          </p>
          <h5>Vectorized cost function</h5>
          <div class="img-section">
            <img src="img/logistic_cost_function_vectorized.png" alt="" class="white">
          </div>
          <div class="section scrollspy">
            <h5>Gradient Descent</h5>
            <hr>
            <p>
              To minimize our cost, we use Gradient Descent just like before in Linear Regression.
            </p>
            <h5>Math</h5>
            <p>
              With respect to our parameters, we use the gradient function for our gradient descent:
            </p>
            <div class="img-section">
              <img src="img/gradient_descent_algo.png" alt="" class="white">
            </div>
            <div class="math">
              <code>
                Repeat {
                  <ol class="flow-text">
                    <li>Calculate gradient average</li>
                    <li>Multiply by learning rate</li>
                    <li>Subtract from <strong>weights</strong></li>
                  </ol>
                }
              </code>
            </div>
          </div>
          <div class="section scrollspy">
            <h5>Training</h5>
            <hr>
            <p>
              Just like linear regression with <strong>gradient descent</strong>, we will initialize our parameters &theta; to a vector of zeros, and update the parameters each epoch using: &theta; = &theta; + &alpha; * gradient of J(&theta;), where &alpha; is our learning rate and J(&theta;) is the cost function of our weights.
              <br><br>
              One more consideration we have to make before writing our training function is that our current classification method only works with two class labels: <b>positive</b> and the rest are <b>negative</b>. In order to classify more than two labels, we will employ whats known as <strong>one-vs.-rest</strong> strategy: For each class label we will fit a set of parameters where that class label is <b>positive</b> and the rest are <b>negative</b>. We can then form a prediction by selecting the max hypothesis h_&theta;(x) for each set of parameters.
            </p>
          </div>
          <div class="section scrollspy">
            <h5>Multiclass logistic regression</h5>
            <hr>
            <p>Instead of <b>y = 0, 1</b> we will expand our definition so that <b>y = 0, 1 ... n</b>. Basically we re-run the binary classification multiple times, once for each class.
            </p>
            <h5>Procedure</h5>
            <ol class="flow-text">
              <li>Divide the problem into n+1 binary classification problems</li>
              <li>For each class...</li>
              <li>Predict the probability the observations are in that class</li>
              <li>Prediction = max(probability of the classes)</li>
            </ol>
            <p>
              For each sub-problem, we select one class (YES) and limp all the others into a second class(NO). Then we pick the calss with the highest predicted value.
            </p>
          </div>
          <div class="section scrollspy">
            <h5>Softmax activation</h5>
            <hr>
            <p>
              The softmax function (softargmax or normalized exponential function) is a function that takes as input a vector of K real numbers, and normalizes it into a probability distribution consisting og K probabilities proportional to the exponentials of the input numbers. That is, prior to applying softmax, some vector components could be negative, or greater than one; and might not sum to 1; but after applying softmax, each component will be in the interval [0, 1] and the components will add up to 1, so that they can be interpreted as probabilities. The standard unit (softmax) function is defined by the formula:
            </p>
            <div class="img-section">
              <img src="img/softmax_formula.JPG" alt="" class="white">
            </div>
            <p>We apply the standard exponential function to each element z_i of the input vector z and normalize these values by dividing the sum of all these exponentials; this normalization ensures that the sum of the components of the output vector &sigma;(z) is 1.</p>
          </div>
        </div>
     </div>
     <!-- Right side content -->
     <div class="col m2 l2 hide-on-med-and-down">
       <ul class="section table-of-contents">
         <h6>Table of contents</h6>
         <li><a href="#cost-function">Cost function</a></li>
         <li><a href="#">rangaha</a></li>
         <li><a href="#">asd</a></li>
       </ul>
     </div>
  <!--[if IE]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <!-- Add your site or application content here -->
  <script src="../../js/vendor/modernizr-3.8.0.min.js"></script>
  <script src="https://code.jquery.com/jquery-3.4.1.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
  <script>
    window.jQuery || document.write('<script src="js/vendor/jquery-3.4.1.min.js"><\/script>')
  </script>

  <!-- Google Analytics: change UA-XXXXX-Y to be your site's ID. -->
  <script>
    window.ga = function () {
      ga.q.push(arguments)
    };
    ga.q = [];
    ga.l = +new Date;
    ga('create', 'UA-XXXXX-Y', 'auto');
    ga('set', 'transport', 'beacon');
    ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async></script>
  <!-- Materialize js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/js/materialize.min.js"></script>
  <script src="../../js/plugins.js"></script>
  <script src="../../js/main.js"></script>
</body>

</html>
